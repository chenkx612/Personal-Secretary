"""
å…·æœ‰è‡ªä¸»å­¦ä¹ å’Œé•¿æœŸè®°å¿†ç®¡ç†åŠŸèƒ½
"""

import os
import json
from datetime import datetime
from typing import List, Dict, Any

from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate, ChatPromptTemplate
from langchain.chains import LLMChain
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.schema import Document

class PersonalMemoryAgent:
    """å…·æœ‰é•¿æœŸè®°å¿†ç®¡ç†èƒ½åŠ›çš„ä¸ªäººåŠ©æ‰‹Agent"""
    
    def __init__(self, deepseek_api_key: str, user_name: str = "ç”¨æˆ·"):
        """
        åˆå§‹åŒ–Agent
        
        Args:
            deepseek_api_key: DeepSeek APIå¯†é’¥
            user_name: ç”¨æˆ·åç§°
        """
        self.user_name = user_name
        self.profile_file = f"user_profile_{user_name}.json"
        
        # é…ç½®DeepSeek API (ä½¿ç”¨OpenAIå…¼å®¹æ¥å£)
        self.llm = ChatOpenAI(
            model="deepseek-chat",
            openai_api_key=deepseek_api_key,
            openai_api_base="https://api.deepseek.com",
            temperature=0.7
        )
        
        # çŸ­æœŸè®°å¿†ï¼šå¯¹è¯å†å²
        self.short_term_memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
        
        # é•¿æœŸè®°å¿†ï¼šå‘é‡æ•°æ®åº“
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            openai_api_key=deepseek_api_key,
            openai_api_base="https://api.deepseek.com"
        )
        
        self.vector_store = Chroma(
            collection_name=f"memory_{user_name}",
            embedding_function=self.embeddings,
            persist_directory=f"./chroma_db_{user_name}"
        )
        
        # ç»“æ„åŒ–ç”¨æˆ·ç”»åƒ
        self.user_profile = self._load_profile()
        
        # æç¤ºè¯æ¨¡æ¿
        self._setup_prompts()
    
    def _setup_prompts(self):
        """è®¾ç½®æç¤ºè¯æ¨¡æ¿"""
        
        # ä¿¡æ¯æå–æç¤ºè¯
        self.extraction_prompt = PromptTemplate(
            input_variables=["conversation", "user_name"],
            template="""
ä»ä»¥ä¸‹å¯¹è¯ä¸­æå–å…³äº{user_name}çš„é‡è¦ä¿¡æ¯ã€‚

å¯¹è¯å†…å®¹ï¼š
{conversation}

è¯·ä»¥JSONæ ¼å¼è¿”å›æå–çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä»¥ä¸‹ç±»åˆ«ï¼ˆå¦‚æœæœ‰ï¼‰ï¼š
- personal_info: ä¸ªäººåŸºæœ¬ä¿¡æ¯ï¼ˆå§“åã€å¹´é¾„ã€èŒä¸šç­‰ï¼‰
- interests: å…´è¶£çˆ±å¥½
- preferences: åå¥½ï¼ˆå–œæ¬¢/ä¸å–œæ¬¢çš„äº‹ç‰©ï¼‰
- goals: ç›®æ ‡å’Œè®¡åˆ’
- experiences: é‡è¦ç»å†å’Œäº‹ä»¶
- relationships: äººé™…å…³ç³»
- habits: ç”Ÿæ´»ä¹ æƒ¯
- concerns: å…³æ³¨çš„é—®é¢˜

åªè¿”å›JSONæ ¼å¼ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ï¼š
"""
        )
        
        # å¯¹è¯ç”Ÿæˆæç¤ºè¯
        self.conversation_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯{user_name}çš„ä¸ªäººAIåŠ©æ‰‹ï¼Œå…·æœ‰é•¿æœŸè®°å¿†èƒ½åŠ›ã€‚

å…³äº{user_name}çš„å·²çŸ¥ä¿¡æ¯ï¼š
{user_profile}

ç›¸å…³å†å²è®°å¿†ï¼š
{relevant_memories}

è¯·åŸºäºè¿™äº›ä¿¡æ¯ï¼Œæä¾›ä¸ªæ€§åŒ–ã€è´´å¿ƒçš„å›å¤ã€‚å¦‚æœå‘ç°ç”¨æˆ·æåˆ°çš„æ–°ä¿¡æ¯ï¼Œè‡ªç„¶åœ°èå…¥å¯¹è¯ã€‚"""),
            ("human", "{input}")
        ])
    
    def _load_profile(self) -> Dict:
        """åŠ è½½ç”¨æˆ·ç”»åƒ"""
        if os.path.exists(self.profile_file):
            with open(self.profile_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {
            "personal_info": {},
            "interests": [],
            "preferences": {"likes": [], "dislikes": []},
            "goals": [],
            "experiences": [],
            "relationships": [],
            "habits": [],
            "concerns": []
        }
    
    def _save_profile(self):
        """ä¿å­˜ç”¨æˆ·ç”»åƒ"""
        with open(self.profile_file, 'w', encoding='utf-8') as f:
            json.dump(self.user_profile, f, ensure_ascii=False, indent=2)
    
    def _retrieve_relevant_memories(self, query: str, k: int = 3) -> str:
        """ä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯"""
        try:
            docs = self.vector_store.similarity_search(query, k=k)
            if docs:
                memories = "\n".join([f"- {doc.page_content}" for doc in docs])
                return memories
            return "æš‚æ— ç›¸å…³å†å²è®°å¿†"
        except:
            return "æš‚æ— ç›¸å…³å†å²è®°å¿†"
    
    def _extract_and_store_info(self, user_input: str, assistant_response: str):
        """ä»å¯¹è¯ä¸­æå–å¹¶å­˜å‚¨ä¿¡æ¯"""
        conversation = f"ç”¨æˆ·: {user_input}\nåŠ©æ‰‹: {assistant_response}"
        
        # ä½¿ç”¨LLMæå–ä¿¡æ¯
        extraction_chain = LLMChain(
            llm=self.llm,
            prompt=self.extraction_prompt
        )
        
        try:
            result = extraction_chain.run(
                conversation=conversation,
                user_name=self.user_name
            )
            
            # è§£æJSONç»“æœ
            extracted_info = json.loads(result)
            
            # æ›´æ–°ç”¨æˆ·ç”»åƒ
            self._update_profile(extracted_info)
            
            # å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
            self._store_to_vector_db(user_input, assistant_response, extracted_info)
            
        except Exception as e:
            print(f"ä¿¡æ¯æå–å‡ºé”™: {e}")
            # å³ä½¿æå–å¤±è´¥ï¼Œä¹Ÿå­˜å‚¨åŸå§‹å¯¹è¯
            self._store_conversation_only(user_input, assistant_response)
    
    def _update_profile(self, extracted_info: Dict):
        """æ›´æ–°ç”¨æˆ·ç”»åƒ"""
        for category, value in extracted_info.items():
            if category in self.user_profile:
                if isinstance(self.user_profile[category], dict):
                    self.user_profile[category].update(value)
                elif isinstance(self.user_profile[category], list):
                    if isinstance(value, list):
                        for item in value:
                            if item not in self.user_profile[category]:
                                self.user_profile[category].append(item)
                    else:
                        if value not in self.user_profile[category]:
                            self.user_profile[category].append(value)
        
        self._save_profile()
    
    def _store_to_vector_db(self, user_input: str, assistant_response: str, extracted_info: Dict):
        """å­˜å‚¨ä¿¡æ¯åˆ°å‘é‡æ•°æ®åº“"""
        timestamp = datetime.now().isoformat()
        
        # åˆ›å»ºæ–‡æ¡£
        doc_content = f"æ—¶é—´: {timestamp}\nç”¨æˆ·è¯´: {user_input}\næå–çš„ä¿¡æ¯: {json.dumps(extracted_info, ensure_ascii=False)}"
        
        doc = Document(
            page_content=doc_content,
            metadata={
                "timestamp": timestamp,
                "user_input": user_input,
                "type": "conversation_with_extraction"
            }
        )
        
        self.vector_store.add_documents([doc])
    
    def _store_conversation_only(self, user_input: str, assistant_response: str):
        """ä»…å­˜å‚¨å¯¹è¯å†…å®¹"""
        timestamp = datetime.now().isoformat()
        doc_content = f"æ—¶é—´: {timestamp}\nç”¨æˆ·: {user_input}\nåŠ©æ‰‹: {assistant_response}"
        
        doc = Document(
            page_content=doc_content,
            metadata={
                "timestamp": timestamp,
                "type": "conversation"
            }
        )
        
        self.vector_store.add_documents([doc])
    
    def chat(self, user_input: str) -> str:
        """
        ä¸ç”¨æˆ·å¯¹è¯
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            
        Returns:
            åŠ©æ‰‹å›å¤
        """
        # 1. æ£€ç´¢ç›¸å…³è®°å¿†
        relevant_memories = self._retrieve_relevant_memories(user_input)
        
        # 2. æ ¼å¼åŒ–ç”¨æˆ·ç”»åƒ
        profile_summary = json.dumps(self.user_profile, ensure_ascii=False, indent=2)
        
        # 3. ç”Ÿæˆå›å¤
        conversation_chain = LLMChain(
            llm=self.llm,
            prompt=self.conversation_prompt
        )
        
        response = conversation_chain.run(
            user_name=self.user_name,
            user_profile=profile_summary,
            relevant_memories=relevant_memories,
            input=user_input
        )
        
        # 4. æ›´æ–°çŸ­æœŸè®°å¿†
        self.short_term_memory.save_context(
            {"input": user_input},
            {"output": response}
        )
        
        # 5. æå–å¹¶å­˜å‚¨é•¿æœŸè®°å¿†ï¼ˆå¼‚æ­¥è¿›è¡Œï¼Œä¸é˜»å¡å“åº”ï¼‰
        try:
            self._extract_and_store_info(user_input, response)
        except Exception as e:
            print(f"è®°å¿†å­˜å‚¨å¤±è´¥: {e}")
        
        return response
    
    def show_profile(self) -> Dict:
        """æ˜¾ç¤ºå½“å‰ç”¨æˆ·ç”»åƒ"""
        return self.user_profile
    
    def clear_memory(self):
        """æ¸…é™¤æ‰€æœ‰è®°å¿†"""
        self.short_term_memory.clear()
        if os.path.exists(self.profile_file):
            os.remove(self.profile_file)
        print("è®°å¿†å·²æ¸…é™¤")


# ä½¿ç”¨ç¤ºä¾‹
def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    
    # é…ç½®APIå¯†é’¥
    DEEPSEEK_API_KEY = "your-deepseek-api-key"  # æ›¿æ¢ä¸ºä½ çš„APIå¯†é’¥
    
    # åˆ›å»ºAgent
    agent = PersonalMemoryAgent(
        deepseek_api_key=DEEPSEEK_API_KEY,
        user_name="å¼ ä¸‰"
    )
    
    print("ğŸ¤– ä¸ªäººè®°å¿†Agentå·²å¯åŠ¨ï¼")
    print("æˆ‘ä¼šè®°ä½æˆ‘ä»¬å¯¹è¯ä¸­çš„é‡è¦ä¿¡æ¯ï¼Œå¹¶åœ¨æœªæ¥çš„å¯¹è¯ä¸­ä½¿ç”¨è¿™äº›è®°å¿†ã€‚")
    print("è¾“å…¥ 'exit' é€€å‡ºï¼Œ'profile' æŸ¥çœ‹æˆ‘å¯¹ä½ çš„äº†è§£\n")
    
    while True:
        user_input = input("ä½ : ").strip()
        
        if user_input.lower() == 'exit':
            print("å†è§ï¼æˆ‘ä¼šè®°ä½æˆ‘ä»¬çš„å¯¹è¯ ğŸ˜Š")
            break
        
        if user_input.lower() == 'profile':
            print("\nğŸ“‹ å½“å‰ç”¨æˆ·ç”»åƒï¼š")
            print(json.dumps(agent.show_profile(), ensure_ascii=False, indent=2))
            print()
            continue
        
        if not user_input:
            continue
        
        # è·å–å›å¤
        response = agent.chat(user_input)
        print(f"\nğŸ¤– åŠ©æ‰‹: {response}\n")


if __name__ == "__main__":
    main()